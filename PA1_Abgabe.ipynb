{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f969a0b560d30e6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Programming Assignment 1\n",
    "## Genre Classification using Locality Sensitive Hashing (LSH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "188d6f0bdc488332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T11:08:47.280590Z",
     "start_time": "2024-04-03T11:08:46.312503Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d26fafdb1a7f08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Loading and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7071a521eb16897a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:13:45.630655Z",
     "start_time": "2024-04-04T09:13:32.332003Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Do the indcies of X_train get mixed up? I think this\n",
    "\"\"\"\n",
    "# Load data\n",
    "df_tracks = pd.read_csv('tracks.csv', index_col=0, header=[0, 1])\n",
    "df_tracks = df_tracks[df_tracks['set']['subset'] == 'medium']\n",
    "df_features = pd.read_csv('features.csv', index_col=0, header=[0, 1, 2])\n",
    "\n",
    "# Filter by genres\n",
    "df_tracks = df_tracks[df_tracks['track']['genre_top'].isin(['Hip-Hop', 'Pop', 'Folk', 'Rock', 'Experimental', 'International', 'Electronic', 'Instrumental'])]\n",
    "\n",
    "# Split df_tracks into training, testing, and validation sets\n",
    "df_tracks_train = df_tracks[df_tracks.iloc[:, 30] == 'training']\n",
    "df_tracks_test = df_tracks[df_tracks.iloc[:, 30] == 'test']\n",
    "df_tracks_validation = df_tracks[df_tracks.iloc[:, 30] == 'validation']\n",
    "\n",
    "# Match features with tracks for training, testing, and validation\n",
    "df_features_train = df_features[df_features.index.isin(df_tracks_train.index)]\n",
    "df_features_test = df_features[df_features.index.isin(df_tracks_test.index)]\n",
    "df_features_validation = df_features[df_features.index.isin(df_tracks_validation.index)]\n",
    "\n",
    "\n",
    "# Create tuples of (data, indices) for each dataset\n",
    "train_data_with_indices = (df_features_train.values, df_features_train.index)\n",
    "test_data_with_indices = (df_features_test.values, df_features_test.index)\n",
    "validation_data_with_indices = (df_features_validation.values, df_features_validation.index)\n",
    "\n",
    "\"\"\"\n",
    "# Extract feature values\n",
    "X_train = df_features_train.values\n",
    "X_test = df_features_test.values\n",
    "X_validation = df_features_validation.values\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Extract genre labels\n",
    "y_train = df_tracks_train['track']['genre_top']\n",
    "y_test = df_tracks_test['track']['genre_top']\n",
    "y_validation = df_tracks_validation['track']['genre_top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1af47e0a67272147",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:16:24.330693Z",
     "start_time": "2024-04-04T09:16:24.325118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming train_data_with_indices is a tuple in the form (X_train, indices_train)\n",
    "X_debug, indices_debug = train_data_with_indices  # Unpack the tuple\n",
    "\n",
    "# Now, take the first 5 elements from both X_debug and indices_debug\n",
    "X_debug_first5 = X_debug[:5]\n",
    "indices_debug_first5 = indices_debug[:5]\n",
    "\n",
    "# If you need to recombine these into a tuple format for some operation\n",
    "debug_data_with_indices_first5 = (X_debug_first5, indices_debug_first5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1630ebed9cf7cb33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Projection Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da1edd32a365c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T11:08:48.850893Z",
     "start_time": "2024-04-03T11:08:48.846039Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r_i = rowsize, r_j) = columsize\n",
    "def generate_random_matrix(r_i, r_j):\n",
    "    rij = np.random.choice([-1, 0, 1], size=(r_i, r_j), p=[1/6, 2/3, 1/6])\n",
    "    return np.sqrt(3) * rij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a78f1eab6b5828",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hashtable generator function\n",
    "\n",
    "We use the transpose of the Random Projection Matrix to reduce the dimensionality  and determine the orientation of each track's data relative to the hyperplanes by using the dot Product of the feature matrix and the transposed Random Projection Matrix. \n",
    "Then we use the binary representations of the orientations as a bucket and put in the tracks accordingly. \n",
    "$ \\begin{cases} \n",
    "0 & \\text{ if } x < 0 \\\\\n",
    "1 & \\text{ else}\n",
    "\\end{cases}\n",
    "$ \n",
    "We can do this because of $\\mathbf{a} \\cdot \\mathbf{b} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\| \\cos(\\theta)$ positive means on one side and negative on the other.\n",
    "This whole process represents one hashtable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a787572460aa4b47",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:16:30.830668Z",
     "start_time": "2024-04-04T09:16:30.823885Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The binary representations are of length l.\n",
    "And the number of hashtables we creat is equal to n.\n",
    "\"\"\"\n",
    "def hashtable_generator(data_indices_tuple, l=32, n=20):\n",
    "    X, indices = data_indices_tuple  # Unpack the tuple into data and indices\n",
    "    hash_tables_and_matrices = []\n",
    "    for _ in range(n):\n",
    "        buckets = {}\n",
    "        random_matrix = generate_random_matrix(l, X.shape[1])\n",
    "        X_dot = np.dot(X, random_matrix.T)\n",
    "        X_dot = X_dot > 0\n",
    "        X_dot = X_dot.astype(int)\n",
    "\n",
    "\n",
    "        for i in range(len(X_dot)):\n",
    "            hash_str = ''.join(X_dot[i].astype(str))\n",
    "            if hash_str not in buckets:\n",
    "                buckets[hash_str] = []\n",
    "            buckets[hash_str].append(indices[i])  # Use the original DataFrame index\n",
    "        \n",
    "        hash_tables_and_matrices.append((buckets, random_matrix))\n",
    "    \n",
    "    return hash_tables_and_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hash_debug = (hashtable_generator(debug_data_with_indices_first5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:20:02.759037Z",
     "start_time": "2024-04-04T09:20:02.731797Z"
    }
   },
   "id": "bc6e898917966faa",
   "execution_count": 148
  },
  {
   "cell_type": "markdown",
   "id": "b077d89ac069c55c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Similar Songs Finder\n",
    "In this step we use the computed hash_tables and the according matrices to find all similar songs of the input song. \n",
    "> A music track is defined as similar if it is in the same bucket as $t_i$ in one of the $n$ hash tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "29345eb53e985117",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:20:07.464738Z",
     "start_time": "2024-04-04T09:20:07.458978Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_similar_songs(song_input, hash_tables_and_matrices):\n",
    "    \"\"\"\n",
    "    Finds and returns the original DataFrame indices of songs similar to the given input song.\n",
    "    \n",
    "    Parameters:\n",
    "    - song_input: The feature array of the song for which similar songs are to be found.\n",
    "    - hash_tables_and_matrices: A list of tuples, where each tuple contains a hash table (dictionary)\n",
    "      of song indices keyed by their hash, and the random matrix used to project the songs into hash space.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of the original DataFrame indices of songs similar to the input song.\n",
    "    \"\"\"\n",
    "    similar_songs_indices = set()\n",
    "\n",
    "    for buckets, random_matrix in hash_tables_and_matrices:\n",
    "        # Project the input song using the random matrix and generate its hash\n",
    "        song_projected = np.dot(song_input, random_matrix.T) > 0\n",
    "        song_hash = ''.join(song_projected.astype(int).astype(str))\n",
    "\n",
    "        # If the hash is found in the buckets, update the set of similar song indices\n",
    "        if song_hash in buckets:\n",
    "            similar_songs_indices.update(buckets[song_hash])\n",
    "\n",
    "    return list(similar_songs_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sim_debug = find_similar_songs(X_debug[0], hash_debug)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:24:05.457774Z",
     "start_time": "2024-04-04T09:24:05.452010Z"
    }
   },
   "id": "4ea4ed173cd294e3",
   "execution_count": 152
  },
  {
   "cell_type": "markdown",
   "id": "8f6b294b",
   "metadata": {},
   "source": [
    "same but for multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6b617c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_song_multiple( times, song_input):\n",
    "    found_categories = []\n",
    "    for _ in range(times):\n",
    "        print(\"doing it times \", _)\n",
    "        local_categories = find_similar_songs(song_input,hashtable_generator(X_train))\n",
    "        if len(local_categories) == 0:\n",
    "            continue\n",
    "        genres = []\n",
    "        for element in local_categories:\n",
    "            genres.append(y_train.iloc[element[0]])\n",
    "        found_categories.append(max(set(genres), key=genres.count))\n",
    "        #TODO check if reset necessary\n",
    "        #self.reset()\n",
    "    return max(set(found_categories), key=found_categories.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa69ae79ff5f23d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Distance Computation of Similar Songs\n",
    "This function computes the distance of all similar Songs to the input Song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "28bf0c05ba9bd8fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:29:41.016110Z",
     "start_time": "2024-04-04T09:29:41.008699Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_distances(train_data_with_indices, song_input, similar_songs_indices, metric=\"euclid\", cut=10):\n",
    "    X_data, X_indices = train_data_with_indices  # Unpack the tuple\n",
    "    index_to_position = {index: pos for pos, index in enumerate(X_indices)}\n",
    "    \n",
    "    filtered_songs = []\n",
    "    if metric == \"euclid\":\n",
    "        for index in similar_songs_indices:\n",
    "            pos = index_to_position[index]\n",
    "            distance = np.linalg.norm(X_data[pos] - song_input)\n",
    "            filtered_songs.append((index, distance))\n",
    "    elif metric == \"cosine\":\n",
    "        for index in similar_songs_indices:\n",
    "            pos = index_to_position[index]\n",
    "            # Cosine similarity\n",
    "            dot_product = np.dot(X_data[pos], song_input)\n",
    "            norm_song = np.linalg.norm(X_data[pos])\n",
    "            norm_input = np.linalg.norm(song_input)\n",
    "            similarity = dot_product / (norm_song * norm_input)\n",
    "            \n",
    "            # Convert similarity to distance (cosine distance)\n",
    "            distance = 1 - similarity\n",
    "            filtered_songs.append((index, distance))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric specified. Use 'euclid' or 'cosine'.\")\n",
    "\n",
    "    sorted_songs = sorted(filtered_songs, key=lambda x: x[1])\n",
    "    if cut is not None:\n",
    "        sorted_songs = sorted_songs[:cut]\n",
    "    \n",
    "    return [index for index, _ in sorted_songs]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 134, 139, 198, 136]\n"
     ]
    }
   ],
   "source": [
    "print(compute_distances(debug_data_with_indices_first5, X_debug[0], sim_debug))\n",
    "matching_s = compute_distances(debug_data_with_indices_first5, X_debug[0], sim_debug)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:29:42.011817Z",
     "start_time": "2024-04-04T09:29:42.006547Z"
    }
   },
   "id": "58faa1a962ae41d4",
   "execution_count": 162
  },
  {
   "cell_type": "markdown",
   "id": "b79bc0c9ab605fc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Getting the Genre by Majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b7b6efe9d0536591",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:29:43.506456Z",
     "start_time": "2024-04-04T09:29:43.500665Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def determine_genre_by_majority_vote(song_indices, Y):\n",
    "    \"\"\"\n",
    "    Determines the most common genre among the given song indices.\n",
    "\n",
    "    Parameters:\n",
    "    - song_indices: A list of indices for the songs.\n",
    "    - Y: A pandas Series where the index corresponds to song indices and the values to genres.\n",
    "\n",
    "    Returns:\n",
    "    - The genre that occurs most frequently among the given songs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure Y is a pandas Series to use .loc efficiently\n",
    "    if not isinstance(Y, pd.Series):\n",
    "        raise ValueError(\"Y must be a pandas Series mapping song indices to genres.\")\n",
    "\n",
    "    # Filter song_indices to ensure they are within the range of Y's index\n",
    "    valid_indices = [i for i in song_indices if i in Y.index]\n",
    "    \n",
    "    # Extract the genres for the given (valid) indices\n",
    "    genres = Y.loc[valid_indices]\n",
    "\n",
    "    # Use value_counts() to count and find the most common genre efficiently\n",
    "    majority_genre = genres.value_counts().idxmax()\n",
    "    \n",
    "    return majority_genre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9daeaf5ba2ef3f7a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T09:29:44.130925Z",
     "start_time": "2024-04-04T09:29:44.124598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Hip-Hop'"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_genre_by_majority_vote(matching_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9611199a20838623",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "0.3993485342019544\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy_with_find_matching_songs_multiple_optimized(times):\n",
    "    correct = 0\n",
    "    two_d_array = [[0 for _ in range(times)] for _ in range(len(X_test))]\n",
    "    for _ in range(times):\n",
    "        print(\"iteration\",_)\n",
    "        table = hashtable_generator(X_train)\n",
    "        for i in range(len(X_test)):\n",
    "            song = X_test[i]\n",
    "            genres = []\n",
    "            matching_songs = find_similar_songs(song,table)\n",
    "            if len(matching_songs) == 0:\n",
    "                continue\n",
    "            for element in matching_songs:\n",
    "                genres.append(y_train.iloc[element])  # Remove [0] subscript here\n",
    "            two_d_array[i][_] = (max(set(genres), key=genres.count))\n",
    "    for i in range(len(X_test)):\n",
    "        genres = [two_d_array[i][_] for _ in range(times)]\n",
    "        if max(set(genres), key=genres.count) == y_test.iloc[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct/len(X_test)\n",
    "    #print(f\"Accuracy Test set advanced: {accuracy}\")\n",
    "    return accuracy\n",
    "print(test_accuracy_with_find_matching_songs_multiple_optimized(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
