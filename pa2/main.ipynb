{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear SVMs using the original features:\n",
      "Toydata SGD Training Time: 2.38 seconds\n",
      "Toydata SGD Accuracy: 0.50\n",
      "Toydata Adagrad Training Time: 2.65 seconds\n",
      "Toydata Adagrad Accuracy: 0.50\n",
      "Toydata_large SGD Training Time: 2.62 seconds\n",
      "Toydata_large SGD Accuracy: 0.50\n",
      "Toydata_large Adagrad Training Time: 5.75 seconds\n",
      "Toydata_large Adagrad Accuracy: 0.50\n",
      "\n",
      "Training SVMs using Gaussian RFFs:\n",
      "Using 100 RFF features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\random_projection.py:408: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 100).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toydata RFF Training Time: 6.40 seconds\n",
      "Toydata RFF Accuracy: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\random_projection.py:408: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 100).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toydata_large RFF Training Time: 5.50 seconds\n",
      "Toydata_large RFF Accuracy: 0.50\n",
      "Using 300 RFF features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\random_projection.py:408: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 300).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toydata RFF Training Time: 7.05 seconds\n",
      "Toydata RFF Accuracy: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\random_projection.py:408: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 300).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toydata_large RFF Training Time: 6.92 seconds\n",
      "Toydata_large RFF Accuracy: 0.50\n",
      "Using 500 RFF features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\random_projection.py:408: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 500).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toydata RFF Training Time: 6.65 seconds\n",
      "Toydata RFF Accuracy: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\sklearn\\random_projection.py:408: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 500).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toydata_large RFF Training Time: 8.46 seconds\n",
      "Toydata_large RFF Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, C=1.0, eta=0.01, max_iter=1000, tol=1e-5):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def hinge_loss(self, X, y):\n",
    "        \"\"\"Compute the hinge loss for the given data and current model parameters.\"\"\"\n",
    "        z = y * (np.dot(X, self.w) + self.b)\n",
    "        return np.maximum(0, 1 - z).mean()\n",
    "\n",
    "    def fit(self, X, y, method='sgd'):\n",
    "        \"\"\"Train the SVM model using the specified optimization method.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        if method == 'sgd':\n",
    "            self.fit_sgd(X, y)\n",
    "        elif method == 'adagrad':\n",
    "            self.fit_adagrad(X, y)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimization method. Use 'sgd' or 'adagrad'.\")\n",
    "\n",
    "    def fit_sgd(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i in range(n_samples):\n",
    "                sample = X[i]\n",
    "                label = y[i]\n",
    "                margin = label * (np.dot(self.w, sample) + self.b)\n",
    "                if margin < 1:\n",
    "                    grad_w = self.C * label * sample - self.w\n",
    "                    grad_b = self.C * label\n",
    "                    # Gradient clipping\n",
    "                    grad_norm = np.linalg.norm(grad_w)\n",
    "                    if grad_norm > 1:\n",
    "                        grad_w = grad_w / grad_norm\n",
    "                    self.w = self.w - self.eta * grad_w\n",
    "                    self.b = self.b - self.eta * grad_b\n",
    "            if self.hinge_loss(X, y) < self.tol:\n",
    "                break\n",
    "\n",
    "    def fit_adagrad(self, X, y):\n",
    "        \"\"\"Train the SVM model using Adagrad optimization.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        G_w = np.zeros(n_features)\n",
    "        G_b = 0\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i in range(n_samples):\n",
    "                sample = X[i]\n",
    "                label = y[i]\n",
    "                margin = label * (np.dot(self.w, sample) + self.b)\n",
    "                if margin < 1:\n",
    "                    grad_w = self.C * label * sample - self.w\n",
    "                    grad_b = self.C * label\n",
    "                    G_w += grad_w ** 2\n",
    "                    G_b += grad_b ** 2\n",
    "                    self.w = self.w - self.eta / np.sqrt(G_w) * grad_w\n",
    "                    self.b = self.b - self.eta / np.sqrt(G_b) * grad_b\n",
    "            if self.hinge_loss(X, y) < self.tol:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for the given data.\"\"\"\n",
    "        y_pred = np.where(np.isnan(np.dot(X, self.w) + self.b), 0, np.sign(np.dot(X, self.w) + self.b))\n",
    "        return y_pred\n",
    "\n",
    "# Load data\n",
    "toydata = pd.read_csv('toydata_tiny.csv')\n",
    "X_toy = toydata.iloc[:, :-1].values\n",
    "y_toy = toydata.iloc[:, -1].values\n",
    "\n",
    "toydata_large = pd.read_csv('toydata_large.csv')\n",
    "X_toy_large = X_toy\n",
    "y_toy_large = y_toy\n",
    "imdb_data = np.load('imdb.npz', allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Train linear SVMs using the original features\n",
    "print(\"Training linear SVMs using the original features:\")\n",
    "\n",
    "# Toydata\n",
    "svm_sgd_toy = SVM(C=1.0, eta=0.01, max_iter=1000, tol=1e-5)\n",
    "start_time = time.time()\n",
    "svm_sgd_toy.fit(X_toy, y_toy, method='sgd')\n",
    "sgd_runtime_toy = time.time() - start_time\n",
    "sgd_accuracy_toy = accuracy_score(y_toy, svm_sgd_toy.predict(X_toy))\n",
    "print(f\"Toydata SGD Training Time: {sgd_runtime_toy:.2f} seconds\")\n",
    "print(f\"Toydata SGD Accuracy: {sgd_accuracy_toy:.2f}\")\n",
    "\n",
    "svm_adagrad_toy = SVM(C=1.0, eta=0.01, max_iter=1000, tol=1e-5)\n",
    "start_time = time.time()\n",
    "svm_adagrad_toy.fit(X_toy, y_toy, method='adagrad')\n",
    "adagrad_runtime_toy = time.time() - start_time\n",
    "adagrad_accuracy_toy = accuracy_score(y_toy, svm_adagrad_toy.predict(X_toy))\n",
    "print(f\"Toydata Adagrad Training Time: {adagrad_runtime_toy:.2f} seconds\")\n",
    "print(f\"Toydata Adagrad Accuracy: {adagrad_accuracy_toy:.2f}\")\n",
    "\n",
    "# Toydata_large\n",
    "svm_sgd_toy_large = SVM(C=1.0, eta=0.01, max_iter=1000, tol=1e-5)\n",
    "start_time = time.time()\n",
    "svm_sgd_toy_large.fit(X_toy_large, y_toy_large, method='sgd')\n",
    "sgd_runtime_toy_large = time.time() - start_time\n",
    "sgd_accuracy_toy_large = accuracy_score(y_toy_large, svm_sgd_toy_large.predict(X_toy_large))\n",
    "print(f\"Toydata_large SGD Training Time: {sgd_runtime_toy_large:.2f} seconds\")\n",
    "print(f\"Toydata_large SGD Accuracy: {sgd_accuracy_toy_large:.2f}\")\n",
    "\n",
    "svm_adagrad_toy_large = SVM(C=1.0, eta=0.01, max_iter=1000, tol=1e-5)\n",
    "start_time = time.time()\n",
    "svm_adagrad_toy_large.fit(X_toy_large, y_toy_large, method='adagrad')\n",
    "adagrad_runtime_toy_large = time.time() - start_time\n",
    "adagrad_accuracy_toy_large = accuracy_score(y_toy_large, svm_adagrad_toy_large.predict(X_toy_large))\n",
    "print(f\"Toydata_large Adagrad Training Time: {adagrad_runtime_toy_large:.2f} seconds\")\n",
    "print(f\"Toydata_large Adagrad Accuracy: {adagrad_accuracy_toy_large:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train SVMs using Gaussian RFFs\n",
    "print(\"\\nTraining SVMs using Gaussian RFFs:\")\n",
    "\n",
    "for n_rff in [100, 300, 500]:\n",
    "    print(f\"Using {n_rff} RFF features:\")\n",
    "\n",
    "    # Toydata\n",
    "    rff = GaussianRandomProjection(n_components=n_rff, random_state=42)\n",
    "    X_toy_rff = rff.fit_transform(X_toy)\n",
    "    svm_rff_toy = SVM(C=1.0, eta=0.01, max_iter=1000, tol=1e-5)\n",
    "    start_time = time.time()\n",
    "    svm_rff_toy.fit(X_toy_rff, y_toy, method='sgd')\n",
    "    rff_runtime_toy = time.time() - start_time\n",
    "    rff_accuracy_toy = accuracy_score(y_toy, svm_rff_toy.predict(X_toy_rff))\n",
    "    print(f\"Toydata RFF Training Time: {rff_runtime_toy:.2f} seconds\")\n",
    "    print(f\"Toydata RFF Accuracy: {rff_accuracy_toy:.2f}\")\n",
    "\n",
    "    # Toydata_large\n",
    "    X_toy_large_rff = rff.fit_transform(X_toy_large)\n",
    "    svm_rff_toy_large = SVM(C=1.0, eta=0.01, max_iter=1000, tol=1e-5)\n",
    "    start_time = time.time()\n",
    "    svm_rff_toy_large.fit(X_toy_large_rff, y_toy_large, method='sgd')\n",
    "    rff_runtime_toy_large = time.time() - start_time\n",
    "    rff_accuracy_toy_large = accuracy_score(y_toy_large, svm_rff_toy_large.predict(X_toy_large_rff))\n",
    "    print(f\"Toydata_large RFF Training Time: {rff_runtime_toy_large:.2f} seconds\")\n",
    "    print(f\"Toydata_large RFF Accuracy: {rff_accuracy_toy_large:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
