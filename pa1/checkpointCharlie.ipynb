{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f969a0b560d30e6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Programming Assignment 1\n",
    "## Genre Classification using Locality Sensitive Hashing (LSH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbabf9e",
   "metadata": {},
   "source": [
    "# README How to use this Notebook\n",
    "\n",
    "## Introduction\n",
    "This readme describes how to use the pa1.ipynb file in this directory. \n",
    "\n",
    "## Getting Started\n",
    "To get started, make sure you have all the necessary Python imports installed. If any of the imports are missing, you can use the `pip install` command to install the required dependencies. Alternatively, you can use an IDE like PyCharm, which may assist you in resolving any dependency issues.\n",
    "\n",
    "## Running the Notebook\n",
    "To run this notebook, simply execute each cell in sequential order. Each cell contains a block of code or markdown text that serves a specific purpose. You can run the cells individually or use the \"Run All\" option to execute all cells at once.\n",
    "For the data make sure that the two files `tracks.csv` and `features.csv` are in the same directory as this notebook!\n",
    "\n",
    "## Important Note\n",
    "Please note that the parameter optimization at the end of the notebook can be time-consuming. If you wish, you can skip the last few cells to save time. However, keep in mind that skipping these cells may affect the accuracy of the genre classification.\n",
    "\n",
    "## Need Help?\n",
    "If you encounter any issues or have any questions, please feel free to reach out to us. Your professor should have our contact information. Alternatively as a student, you can ask for assistance in the Computer Science Discord server. Make sure to post your question in the correct channel (MMD), and we will be happy to help you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a78e6",
   "metadata": {},
   "source": [
    "# Imports for the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188d6f0bdc488332",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:28.905988Z",
     "start_time": "2024-04-06T11:43:28.887035Z"
    }
   },
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "27d26fafdb1a7f08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Loading and Preprocessing \n",
    "Loads the data from the csv, please make sure to have the two csv files tracks & featrues.csv in the same directory as this notebook !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7071a521eb16897a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.486982Z",
     "start_time": "2024-04-06T11:43:28.912001Z"
    }
   },
   "source": [
    "\n",
    "# Load data\n",
    "df_tracks = pd.read_csv('tracks.csv', index_col=0, header=[0, 1])\n",
    "df_tracks = df_tracks[df_tracks['set']['subset'] == 'medium']\n",
    "df_features = pd.read_csv('features.csv', index_col=0, header=[0, 1, 2])\n",
    "\n",
    "# Filter by genres\n",
    "df_tracks = df_tracks[df_tracks['track']['genre_top'].isin(['Hip-Hop', 'Pop', 'Folk', 'Rock', 'Experimental', 'International', 'Electronic', 'Instrumental'])]\n",
    "\n",
    "# Split df_tracks into training, testing, and validation sets\n",
    "df_tracks_train = df_tracks[df_tracks.iloc[:, 30] == 'training']\n",
    "df_tracks_test = df_tracks[df_tracks.iloc[:, 30] == 'test']\n",
    "df_tracks_validation = df_tracks[df_tracks.iloc[:, 30] == 'validation']\n",
    "\n",
    "# Match features with tracks for training, testing, and validation\n",
    "df_features_train = df_features[df_features.index.isin(df_tracks_train.index)]\n",
    "df_features_test = df_features[df_features.index.isin(df_tracks_test.index)]\n",
    "df_features_validation = df_features[df_features.index.isin(df_tracks_validation.index)]\n",
    "\n",
    "# Extract feature values\n",
    "X_train = df_features_train.values\n",
    "X_test = df_features_test.values\n",
    "X_validation = df_features_validation.values\n",
    "\n",
    "# Extract genre labels\n",
    "y_train = df_tracks_train['track']['genre_top']\n",
    "y_test = df_tracks_test['track']['genre_top']\n",
    "y_validation = df_tracks_validation['track']['genre_top']\n",
    "\n",
    "# create smaller test subset from test\n",
    "X_test_small = X_test[:25]\n",
    "y_test_small = y_test[:25]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1630ebed9cf7cb33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Projection Matrix\n",
    "\n",
    "This generates a random matrix which is then used in order to create the hashing . For details look into the paper mentioned in the assigment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da1edd32a365c5f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.514327Z",
     "start_time": "2024-04-06T11:43:45.496982Z"
    }
   },
   "source": [
    "# r_i = rowsize, r_j) = columsize\n",
    "def generate_random_matrix(r_i, r_j):\n",
    "    \"\"\"\n",
    "    Generates a random matrix of size (r_i, r_j) with elements randomly chosen from the set {-1, 0, 1}.\n",
    "    The probabilities of choosing -1, 0, and 1 are 1/6, 2/3, and 1/6 respectively.\n",
    "\n",
    "    Parameters:\n",
    "    r_i (int): The number of rows in the matrix.\n",
    "    r_j (int): The number of columns in the matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The generated random matrix.\n",
    "    \"\"\"\n",
    "    rij = np.random.choice([-1, 0, 1], size=(r_i, r_j), p=[1/6, 2/3, 1/6])\n",
    "    return np.sqrt(3) * rij"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e7a78f1eab6b5828",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hashtable generator function\n",
    "\n",
    "We use the transpose of the Random Projection Matrix to reduce the dimensionality  and determine the orientation of each track's data relative to the hyperplanes by using the dot Product of the feature matrix and the transposed Random Projection Matrix. \n",
    "Then we use the binary representations of the orientations as a bucket and put in the tracks accordingly. \n",
    "$ \\begin{cases} \n",
    "0 & \\text{ if } x < 0 \\\\\n",
    "1 & \\text{ else}\n",
    "\\end{cases}\n",
    "$ \n",
    "We can do this because of $\\mathbf{a} \\cdot \\mathbf{b} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\| \\cos(\\theta)$ positive means on one side and negative on the other.\n",
    "This whole process represents one hashtable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a787572460aa4b47",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.527467Z",
     "start_time": "2024-04-06T11:43:45.517332Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "The binary representations are of length l.\n",
    "And the number of hashtables we creat is equal to n.\n",
    "\"\"\"\n",
    "def hashtable_generator(X, l=64, n=2):\n",
    "    hash_tables_and_matrices = []  \n",
    "    for _ in range(n):\n",
    "        buckets = {}\n",
    "        random_matrix = generate_random_matrix(l, X.shape[1])\n",
    "        X_dot = np.dot(X, random_matrix.T)\n",
    "        X_dot = X_dot > 0\n",
    "        X_dot = X_dot.astype(int)\n",
    "\n",
    "        for i in range(len(X_dot)):\n",
    "            hash_str = ''.join(X_dot[i].astype(str))\n",
    "            if hash_str not in buckets:\n",
    "                buckets[hash_str] = []\n",
    "            buckets[hash_str].append(i)\n",
    "        \n",
    "        hash_tables_and_matrices.append((buckets, random_matrix))\n",
    "        \n",
    "    \n",
    "    return hash_tables_and_matrices\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b077d89ac069c55c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Similar Songs Finder\n",
    "In this step we use the computed hash_tables and the according matrices to find all similar songs of the input song. \n",
    "> A music track is defined as similar if it is in the same bucket as $t_i$ in one of the $n$ hash tables.\n",
    " \n",
    "If no exact matches are found in any bucket, we proceed to calculate the Hamming distance between the bucket and other buckets and choose similar buckets and then return the songs of similar buckets in order to avoide the case that no songs are found. Furthermore we use this technique if there less than 3 songs found in order to improve the accuracy as in the next step the exact distance is calculated anyway. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29345eb53e985117",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.545360Z",
     "start_time": "2024-04-06T11:43:45.529479Z"
    }
   },
   "source": [
    "import itertools\n",
    "\n",
    "def find_similar_songs(song_input, hash_tables_and_matrices):\n",
    "    \"\"\"\n",
    "    Finds similar songs based on the input song and a list of hash tables and matrices.\n",
    "\n",
    "    Parameters:\n",
    "    - song_input: numpy array representing the input song\n",
    "    - hash_tables_and_matrices: list of tuples containing hash tables and random matrices\n",
    "\n",
    "    Returns:\n",
    "    - List of indices of similar songs\n",
    "    \"\"\"\n",
    "\n",
    "    similar_songs_indices = set()\n",
    "\n",
    "    # First, try to find an exact match in any of the hash table and matrix combinations\n",
    "    for buckets, random_matrix in hash_tables_and_matrices:\n",
    "        song_projected = np.dot(song_input, random_matrix.T) > 0\n",
    "        song_hash = ''.join(song_projected.astype(int).astype(str))\n",
    "\n",
    "        if song_hash in buckets:\n",
    "            similar_songs_indices.update(buckets[song_hash])\n",
    "\n",
    "    # If no exact match is found in any combination, try to find the closest 10 buckets\n",
    "    if len(similar_songs_indices) < 3:\n",
    "        #print(\"empty bucket\")\n",
    "        closest_bucket_names = []\n",
    "        min_hamming_distances = []\n",
    "\n",
    "        for buckets, random_matrix in hash_tables_and_matrices:\n",
    "            song_projected = np.dot(song_input, random_matrix.T) > 0\n",
    "            song_hash = ''.join(song_projected.astype(int).astype(str))\n",
    "\n",
    "            bucket_hamming_distances = [(hamming_distance(song_hash, bucket_name), bucket_name) for bucket_name in buckets.keys()]\n",
    "            bucket_hamming_distances.sort(key=lambda x: x[0])\n",
    "            closest_bucket_names.extend([bucket_name for _, bucket_name in bucket_hamming_distances[:10]])\n",
    "            min_hamming_distances.extend([hamming_dist for hamming_dist, _ in bucket_hamming_distances[:10]])\n",
    "\n",
    "        closest_bucket_names = list(dict.fromkeys(closest_bucket_names))  # Remove duplicates\n",
    "        min_hamming_distances = list(dict.fromkeys(min_hamming_distances))  # Remove duplicates\n",
    "\n",
    "        for bucket_name, min_hamming_distance in zip(closest_bucket_names, min_hamming_distances):\n",
    "            for buckets, _ in hash_tables_and_matrices:\n",
    "                if bucket_name in buckets and buckets[bucket_name]:\n",
    "                    similar_songs_indices.update(buckets[bucket_name])\n",
    "                    break\n",
    "\n",
    "    return list(similar_songs_indices)\n",
    "\n",
    "def hamming_distance(str1, str2):\n",
    "    \"\"\"Calculate the Hamming distance between two binary strings\"\"\"\n",
    "    return sum(c1 != c2 for c1, c2 in zip(str1, str2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7fa69ae79ff5f23d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Distance Computation of Similar Songs\n",
    "This function computes the distance of all similar Songs to the input Song and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bf0c05ba9bd8fd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.559941Z",
     "start_time": "2024-04-06T11:43:45.550369Z"
    }
   },
   "source": [
    "def compute_distances(X, song_input, similar_songs, metric=\"euclid\", cut=10):\n",
    "    \"\"\"\n",
    "    Compute distances between a given song input and a list of similar songs.\n",
    "\n",
    "    Parameters:\n",
    "    - X (numpy.ndarray): Array of songs.\n",
    "    - song_input (numpy.ndarray): Input song to compare distances with.\n",
    "    - similar_songs (list): List of indices of similar songs.\n",
    "    - metric (str, optional): Distance metric to use. Default is \"euclid\".\n",
    "    - cut (int, optional): Number of similar songs to return. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    - list: Indices of the most similar songs based on the specified metric and cut.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If an invalid metric is specified.\n",
    "\n",
    "    \"\"\"\n",
    "    filtered_songs = []\n",
    "    if metric == \"euclid\":\n",
    "        for element in similar_songs:\n",
    "            distance = np.linalg.norm(X[element] - song_input)\n",
    "            filtered_songs.append((element, distance))\n",
    "    elif metric == \"cosine\":\n",
    "        for element in similar_songs:\n",
    "            # cosine similarity\n",
    "            dot_product = np.dot(X[element], song_input)\n",
    "            norm_song = np.linalg.norm(X[element])\n",
    "            norm_input = np.linalg.norm(song_input)\n",
    "            similarity = dot_product / (norm_song * norm_input)\n",
    "            \n",
    "            # From similarity to distance (cosine distance)\n",
    "            distance = 1 - similarity\n",
    "            filtered_songs.append((element, distance))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric specified. Use 'euclid' or 'cosine'.\")\n",
    "    \n",
    "    sorted_songs = sorted(filtered_songs, key=lambda x: x[1])\n",
    "    if cut is not None:\n",
    "        sorted_songs = sorted_songs[:cut]\n",
    "    \n",
    "    return [index for index, _ in sorted_songs]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b79bc0c9ab605fc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Getting the Genre by Majority vote\n",
    "\n",
    "This method just outputs the genre that is most used by the songs that are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b6efe9d0536591",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.567241Z",
     "start_time": "2024-04-06T11:43:45.560947Z"
    }
   },
   "source": [
    "def determine_genre_by_majority_vote(song_indices, Y):\n",
    "    \"\"\"\n",
    "    Determines the genre of a song by majority vote based on a list of song indices and their corresponding genres.\n",
    "\n",
    "    Parameters:\n",
    "    - song_indices (list): A list of indices representing the songs.\n",
    "    - Y (pandas Series): A pandas Series containing the genres of the songs.\n",
    "\n",
    "    Returns:\n",
    "    - str: The genre that appears most frequently in the given list of song indices.\n",
    "\n",
    "    If no similar songs are found, the function returns 'Rock' as the default genre.\n",
    "    \"\"\"\n",
    "    genres = []\n",
    "    for index in song_indices:\n",
    "        genres.append(Y.iloc[index])\n",
    "    if len(genres) == 0:\n",
    "        print(\"No similar songs found.\")\n",
    "        return 'Rock'\n",
    "    return max(set(genres), key=genres.count)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa5c859",
   "metadata": {},
   "source": [
    "### This is the complete Operation\n",
    "\n",
    "This can be used to find the genre for a song which combines most steps described here before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9daeaf5ba2ef3f7a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.577864Z",
     "start_time": "2024-04-06T11:43:45.568247Z"
    }
   },
   "source": [
    "def find_song_genre(song, X, Y, hashtables=None, l=64, n=2, cut=10, metric=\"euclid\"):\n",
    "    \"\"\"\n",
    "    Finds the genre of a given song based on its similarity to other songs in a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - song: The song for which the genre needs to be determined.\n",
    "    - X: The dataset of songs.\n",
    "    - Y: The corresponding genres of the songs in the dataset.\n",
    "    - hashtables: Optional. The hash tables used for efficient nearest neighbor search. If not provided, new hash tables will be generated.\n",
    "    - l: Optional. The number of hash tables to generate. Default is 64.\n",
    "    - n: Optional. The number of hash functions per table. Default is 2.\n",
    "    - cut: Optional. The number of nearest neighbors to consider. Default is 10.\n",
    "    - metric: Optional. The distance metric used for computing distances. Default is \"euclid\".\n",
    "\n",
    "    Returns:\n",
    "    - The genre of the given song.\n",
    "    \"\"\"\n",
    "    if hashtables is None:\n",
    "        hashtables = hashtable_generator(X, l, n)\n",
    "    similar_songs = find_similar_songs(song, hashtables)\n",
    "    nearest_neighbours = compute_distances(X, song, similar_songs, metric, cut)\n",
    "    genre = determine_genre_by_majority_vote(nearest_neighbours, Y)\n",
    "\n",
    "    return genre\n",
    "def find_song_genre(song, X,Y, hashtables = None, l=64, n=2, cut=10, metric=\"euclid\"):\n",
    "    if hashtables is None:\n",
    "        hashtables = hashtable_generator(X,l, n)\n",
    "    similar_songs = find_similar_songs(song, hashtables)\n",
    "    nearest_neighbours = compute_distances(X,song, similar_songs, metric, cut)\n",
    "    genre =  determine_genre_by_majority_vote(nearest_neighbours, Y)\n",
    "    \n",
    "    return genre "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2c5f04",
   "metadata": {},
   "source": [
    "### Test and Validation Score\n",
    "\n",
    "Here we define a function to get the test accuracy. \n",
    "We create the hastables with the training data and then use the testing data to guess the genres of the testing songs and check it against the true lables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c0c967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.589508Z",
     "start_time": "2024-04-06T11:43:45.578871Z"
    }
   },
   "source": [
    "def test_accuracy(l=64, n=2, cut=10, metric=\"euclid\"):\n",
    "    \"\"\"\n",
    "    Calculate the test accuracy and the test time of the find_matching_songs_multiple_optimized algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - l (int): The number of hash functions to be used in the hashtable generator.\n",
    "    - n (int): The number of hashtables to be generated.\n",
    "    - cut (int): The number of nearest neighbors to consider for genre classification.\n",
    "    - metric (str): The distance metric to be used for genre classification.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): The test accuracy of the algorithm.\n",
    "    - test_time (float): The time taken to test the algorithm in seconds.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start time measurement\n",
    "\n",
    "    hashtables = hashtable_generator(X_train, l, n)  # Assuming you have this function defined elsewhere\n",
    "    correct = 0\n",
    "    for index in tqdm(range(len(X_test)), desc=\"Progress\"):\n",
    "        song = X_test[index]\n",
    "        genre = find_song_genre(song, X_train, y_train, hashtables, l, n, cut, metric)  # Assuming you have this function defined elsewhere\n",
    "        if genre == y_test.iloc[index]:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(X_test)\n",
    "    end_time = time.time()  # End time measurement\n",
    "    test_time = end_time - start_time\n",
    "\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "    print(f\"Test time: {test_time} seconds\")\n",
    "    return accuracy, test_time"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5d9fb6c7",
   "metadata": {},
   "source": [
    "### Looking for the best hyperparameter\n",
    "We define a function that takes hyperparameters and returns accuracy and runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2095904f7e9d59c6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T11:43:45.599326Z",
     "start_time": "2024-04-06T11:43:45.590513Z"
    }
   },
   "source": [
    "def find_best_parameters_test(l_values, n_values, cut_values, metric_values):\n",
    "    \"\"\"\n",
    "    Finds the best parameters for the test by iterating through provided values of 'l', 'n', 'cut', and 'metric'.\n",
    "    Saves the parameters, accuracy, and test time for each combination in a dictionary and keeps track of the best accuracy and corresponding parameters.\n",
    "    Finally, prints the best parameters, best accuracy found, the best test time, and the complete results dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - l_values (list): List of values for 'l' to iterate over.\n",
    "    - n_values (list): List of values for 'n' to iterate over.\n",
    "    - cut_values (list): List of values for 'cut' to iterate over.\n",
    "    - metric_values (list): List of metrics to iterate over.\n",
    "\n",
    "    Returns:\n",
    "    - results (dict): A dictionary containing the results.\n",
    "    \"\"\"\n",
    "    results = {}  # Dictionary to save the results\n",
    "    best_accuracy = 0\n",
    "    best_parameters = None\n",
    "    best_time = None\n",
    "    \n",
    "    for l in l_values:\n",
    "        for n in n_values:\n",
    "            for cut in cut_values:\n",
    "                for metric in metric_values:\n",
    "                    # Test the current parameter combination\n",
    "                    accuracy, test_time = test_accuracy(l, n, cut, metric)  # Assuming test_accuracy returns (accuracy, time)\n",
    "                    \n",
    "                    # Save the parameters, accuracy, and test time in the dictionary\n",
    "                    results[(l, n, cut, metric)] = {'accuracy': accuracy, 'time': test_time}\n",
    "                    \n",
    "                    # Update the best parameters, accuracy, and test time if the current accuracy is the best found so far\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_parameters = (l, n, cut, metric)\n",
    "                        best_time = test_time\n",
    "    \n",
    "    # Print the best parameters, accuracy, and test time\n",
    "    print(\"Best parameters:\", best_parameters)\n",
    "    print(f\"Best accuracy: {best_accuracy}, Test time: {best_time} seconds\")\n",
    "    \n",
    "    return results"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2fe9bab266a72bf1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will start with fixed $n$ at $2$  and $k$ at $10$ with a eucliden distance measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd9a268074fd1e74",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T15:37:08.131884Z",
     "start_time": "2024-04-06T15:37:06.626902Z"
    }
   },
   "source": [
    "results = finrintd_best_parameters_test([64, 128, 256], [2, 8, 16], [5, 10, 15], [\"euclid\",\"cosine\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff984178fc91cef4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:05:37.053597Z",
     "start_time": "2024-04-08T10:05:36.558474Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing data to fit the visualization requirements\n",
    "data_euclid = {'Accuracy': [], 'Time': [], 'L': [], 'N': [], 'K': []}\n",
    "data_cosine = {'Accuracy': [], 'Time': [], 'L': [], 'N': [], 'K': []}\n",
    "\n",
    "for (l, n, k, m), values in results.items():\n",
    "    if m == 'euclid':\n",
    "        data_euclid['Accuracy'].append(values['accuracy'])\n",
    "        data_euclid['Time'].append(values['time'])\n",
    "        data_euclid['L'].append(l)\n",
    "        data_euclid['N'].append(n)\n",
    "        data_euclid['K'].append(k)\n",
    "    elif m == 'cosine':\n",
    "        data_cosine['Accuracy'].append(values['accuracy'])\n",
    "        data_cosine['Time'].append(values['time'])\n",
    "        data_cosine['L'].append(l)\n",
    "        data_cosine['N'].append(n)\n",
    "        data_cosine['K'].append(k)\n",
    "\n",
    "df_euclid = pd.DataFrame(data_euclid)\n",
    "df_cosine = pd.DataFrame(data_cosine)\n",
    "\n",
    "# Custom marker function\n",
    "def custom_marker(k):\n",
    "    if k == 5:\n",
    "        return 's'  # square\n",
    "    elif k == 10:\n",
    "        return 'o'  # circle\n",
    "    else:\n",
    "        return 'X'  # cross\n",
    "\n",
    "# Plotting for Euclid\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_euclid, x='Accuracy', y='Time', style='K', hue='L', size='N',\n",
    "                palette='viridis', markers={5: 's', 10: 'o', 15: 'X'}, sizes=(100, 200),\n",
    "                alpha=0.6).set_title('Euclid Metric')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ea85cfce52c8d25",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T10:05:50.677025Z",
     "start_time": "2024-04-08T10:05:50.276332Z"
    }
   },
   "source": [
    "# Plotting for Cosine\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_cosine, x='Accuracy', y='Time', style='K', hue='L', size='N',\n",
    "                palette='viridis', markers={5: 's', 10: 'o', 15: 'X'}, sizes=(100, 200),\n",
    "                alpha=0.6).set_title('Cosine Metric')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4b1df00f",
   "metadata": {},
   "source": [
    "## Briefly discuss your implementation of LSH and of the approximate nearest neighbour algorithm.\n",
    "The implementation of the LSH is pretty close to the one that was discussed in the lecture. In the function \"hashtable_generator\", we use the technique of _____ to place the data into buckets and reduce the dimensity and make it easy to search only in these buckets to find neigbours. In order to find the exact neighbours then we calculate the exact distance between the elements in a bucket and return only the best elements (based on the cut parameter). If no enough elements are found please refer to the own chapter here about that case. \n",
    "\n",
    "\n",
    "## Detail how you trained your algorithm and how you performed the hyperparameter optimization. Report tested parameter and the results for these parameters.\n",
    "\n",
    "\n",
    "\n",
    "## Detail why you settled on a specific choice of l (hash length), n (number of hash tables), k (number of nearest neighbours for the prediction) and similarity measure m.\n",
    "First for the parameter m we found out that the cosin metrics performs slightly better nthan the euclid in most cases, not sure why, however both are pretty similar still.\n",
    "k\n",
    "n\n",
    "For the paraemter l we see a slight tenedency to be better when making it smaller. However only slight difference and the runtime with a bigger l tends to get a bit bigger **check that**\n",
    "\n",
    "\n",
    "## Report the classification accuracy of your algorithm on the test set\n",
    "The final accuracy for the test set we achieved was ___\n",
    "The best final accurcay for both the test and validation set was ___\n",
    "\n",
    "\n",
    "## Comment on why the chosen random projection method could be beneficial to drawing from a Gaussian distribution?\n",
    "keine ahnung lol\n",
    "\n",
    "\n",
    "## Comment on how the runtime of your approximate nearest neighbor algorithm in comparison to that of an exact nearest neighbor search. (You can estimate runtime forthe latter case.) If your implementation is slower than the exact search, speculate about possible reasons; comment on how these aspects might change when working with larger datasets.\n",
    "The runtime is better as I see it. As a exact nns would look and compare all elements with a runtime of O(n^2) at least. Our solution uses hashing and then only does the exact nns for the elements which are in the same buckets, which is most of the times only a fraction of the total tracks. Therefore the runtime is much better and it is mmuch better scalable for large datasets as the one here. I think the time for running our algorithm is also pretty quick and i guess the exact search would take at least 10x longer (however would most likly have a equal or better solution), however I think the tradeoff is not to large and worth it. \n",
    "\n",
    "\n",
    "## Report how you treat music tracks for which there are less than k other similar tracks.\n",
    "So if there are not enough close songs found in the bucket we have a mechanism in order to ensure that some meaningful songs are found. \n",
    "The k is not to relevant here as we just cut of the similiar tracks and provide the best k tracks. However in the case where there is only 0-2 similar tracks found we search other similar buckets in order to ensure that there are enough options for the distance calculation. This distance calculation then uses the most usefull ones, however if none or too few tracks are found the algorithm will not output the best result. Therefore we came up with this idea. It would also be possible to do this only for the 0 songs found case, as else there is an expcetion in the program. Alterantive solution would be to just output a random genre for cases where no song is found but that is a bit to boring. \n",
    "\n",
    "\n",
    "## How much time did you spend on the assignment (including the writing of the report; please provide an average for all of your team members)? This will not be used for grading.\n",
    "Würde mal so 20 pro person schätzen aber not sure\n",
    "\n",
    "## Who did what? This will not be used for grading. This part is meant for you as a group to reflect on whether you shared the workload fairly and make adjustments for the next assignment if you observe imbalances.\n",
    "Nenad did the hashtable generator in detail and looked into the theoretical part. While Alex did all of the validation and test scores. The rest was done pretty much together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "{(64, 2, 5, 'euclid'): {'accuracy': 0.5960912052117264, 'time': 24.61885380744934}, (64, 2, 5, 'cosine'): {'accuracy': 0.603257328990228, 'time': 22.938100814819336}, (64, 2, 10, 'euclid'): {'accuracy': 0.6045602605863192, 'time': 13.467969417572021}, (64, 2, 10, 'cosine'): {'accuracy': 0.6358306188925081, 'time': 57.64990282058716}, (64, 2, 15, 'euclid'): {'accuracy': 0.6156351791530945, 'time': 22.726911306381226}, (64, 2, 15, 'cosine'): {'accuracy': 0.6221498371335505, 'time': 28.7292582988739}, (64, 8, 5, 'euclid'): {'accuracy': 0.6019543973941368, 'time': 75.80211687088013}, (64, 8, 5, 'cosine'): {'accuracy': 0.6013029315960912, 'time': 94.78130793571472}, (64, 8, 10, 'euclid'): {'accuracy': 0.6214983713355049, 'time': 62.507568359375}, (64, 8, 10, 'cosine'): {'accuracy': 0.6397394136807818, 'time': 84.98335456848145}, (64, 8, 15, 'euclid'): {'accuracy': 0.6319218241042345, 'time': 51.65255784988403}, (64, 8, 15, 'cosine'): {'accuracy': 0.6390879478827362, 'time': 101.42146253585815}, (64, 16, 5, 'euclid'): {'accuracy': 0.6026058631921825, 'time': 87.87476873397827}, (64, 16, 5, 'cosine'): {'accuracy': 0.6026058631921825, 'time': 153.76025557518005}, (64, 16, 10, 'euclid'): {'accuracy': 0.6182410423452769, 'time': 93.36437702178955}, (64, 16, 10, 'cosine'): {'accuracy': 0.637785016286645, 'time': 152.69060444831848}, (64, 16, 15, 'euclid'): {'accuracy': 0.6254071661237784, 'time': 99.14065146446228}, (64, 16, 15, 'cosine'): {'accuracy': 0.6429967426710098, 'time': 144.37975645065308}, (128, 2, 5, 'euclid'): {'accuracy': 0.5843648208469056, 'time': 16.8671395778656}, (128, 2, 5, 'cosine'): {'accuracy': 0.5667752442996743, 'time': 23.088200569152832}, (128, 2, 10, 'euclid'): {'accuracy': 0.6071661237785017, 'time': 14.384968280792236}, (128, 2, 10, 'cosine'): {'accuracy': 0.6045602605863192, 'time': 17.734903812408447}, (128, 2, 15, 'euclid'): {'accuracy': 0.5993485342019544, 'time': 16.556803941726685}, (128, 2, 15, 'cosine'): {'accuracy': 0.6026058631921825, 'time': 13.323764324188232}, (128, 8, 5, 'euclid'): {'accuracy': 0.5980456026058631, 'time': 27.06729817390442}, (128, 8, 5, 'cosine'): {'accuracy': 0.6123778501628665, 'time': 28.310436487197876}, (128, 8, 10, 'euclid'): {'accuracy': 0.6149837133550489, 'time': 28.34497857093811}, (128, 8, 10, 'cosine'): {'accuracy': 0.6299674267100978, 'time': 31.942339658737183}, (128, 8, 15, 'euclid'): {'accuracy': 0.6293159609120521, 'time': 21.570100784301758}, (128, 8, 15, 'cosine'): {'accuracy': 0.637785016286645, 'time': 29.112306594848633}, (128, 16, 5, 'euclid'): {'accuracy': 0.603257328990228, 'time': 45.2100670337677}, (128, 16, 5, 'cosine'): {'accuracy': 0.606514657980456, 'time': 55.45202159881592}, (128, 16, 10, 'euclid'): {'accuracy': 0.6201954397394137, 'time': 42.76470232009888}, (128, 16, 10, 'cosine'): {'accuracy': 0.6371335504885993, 'time': 57.937888622283936}, (128, 16, 15, 'euclid'): {'accuracy': 0.634527687296417, 'time': 41.43756341934204}, (128, 16, 15, 'cosine'): {'accuracy': 0.641042345276873, 'time': 49.876665115356445}, (256, 2, 5, 'euclid'): {'accuracy': 0.5654723127035831, 'time': 177.14855098724365}, (256, 2, 5, 'cosine'): {'accuracy': 0.5824104234527687, 'time': 179.3382260799408}, (256, 2, 10, 'euclid'): {'accuracy': 0.5622149837133551, 'time': 235.0748996734619}, (256, 2, 10, 'cosine'): {'accuracy': 0.5804560260586319, 'time': 262.19562244415283}, (256, 2, 15, 'euclid'): {'accuracy': 0.5648208469055375, 'time': 326.68050622940063}, (256, 2, 15, 'cosine'): {'accuracy': 0.5830618892508144, 'time': 220.1879427433014}, (256, 8, 5, 'euclid'): {'accuracy': 0.5980456026058631, 'time': 336.16090202331543}, (256, 8, 5, 'cosine'): {'accuracy': 0.5954397394136808, 'time': 286.43207907676697}, (256, 8, 10, 'euclid'): {'accuracy': 0.606514657980456, 'time': 258.5306091308594}, (256, 8, 10, 'cosine'): {'accuracy': 0.613029315960912, 'time': 445.07422518730164}, (256, 8, 15, 'euclid'): {'accuracy': 0.5973941368078176, 'time': 561.9977328777313}, (256, 8, 15, 'cosine'): {'accuracy': 0.6026058631921825, 'time': 249.47272324562073}, (256, 16, 5, 'euclid'): {'accuracy': 0.5889250814332248, 'time': 428.03207778930664}, (256, 16, 5, 'cosine'): {'accuracy': 0.596742671009772, 'time': 304.70144963264465}, (256, 16, 10, 'euclid'): {'accuracy': 0.6117263843648209, 'time': 451.31062722206116}, (256, 16, 10, 'cosine'): {'accuracy': 0.6260586319218241, 'time': 435.0277695655823}, (256, 16, 15, 'euclid'): {'accuracy': 0.6201954397394137, 'time': 345.5001907348633}, (256, 16, 15, 'cosine'): {'accuracy': 0.6214983713355049, 'time': 372.90727162361145}}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1fbcf6c7ebfc8d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
